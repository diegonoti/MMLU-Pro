# MMLU-Pro

This repository contains the evaluation code for MMLU-Pro, which includes methods for utilizing local computing resources for inference and for invoking APIs.

## Usage

### Local Inference

To run local inference:

```bash
cd scripts/example/
sh eval_llama_2_7b.sh
```

To use the API for inference:

```bash
cd scripts/example/
sh eval_gpt_4.sh
```

